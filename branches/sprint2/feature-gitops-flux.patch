diff --git a/.devcontainer/devcontainer.json b/.devcontainer/devcontainer.json
new file mode 100644
index 0000000..e1c2895
--- /dev/null
+++ b/.devcontainer/devcontainer.json
@@ -0,0 +1,32 @@
+{
+	"name": "k8s devcontainer",
+
+	"image": "mcr.microsoft.com/devcontainers/base:bullseye",
+
+	"features": {
+		"ghcr.io/devcontainers/features/kubectl-helm-minikube:1": {
+			"version": "latest",
+			"helm": "none",
+			"minikube": "none"
+		},
+		"ghcr.io/devcontainers/features/git:1": {}
+	},
+
+	"postCreateCommand": "curl -s https://fluxcd.io/install.sh | bash",
+
+	"mounts": [
+		"source=/var/run/docker.sock,target=/var/run/docker.sock,type=bind",
+		"source=${localEnv:HOME}/.kube,target=/home/vscode/.kube,type=bind,consistency=cached"
+	],
+
+	"customizations": {
+		"vscode": {
+			"extensions": [
+				"ms-kubernetes-tools.vscode-kubernetes",
+				"ms-azuretools.vscode-docker",
+				"weaveworks.vscode-flux",
+				"redhat.vscode-yaml"
+			]
+		}
+	}
+}
\ No newline at end of file
diff --git a/.gitignore b/.gitignore
index 40c0613..ceb5ae8 100644
--- a/.gitignore
+++ b/.gitignore
@@ -12,4 +12,3 @@ env/
 venv/
 
 
-debug.log
\ No newline at end of file
diff --git a/Makefile b/Makefile
new file mode 100644
index 0000000..a1b9ba2
--- /dev/null
+++ b/Makefile
@@ -0,0 +1,44 @@
+REPO = "https://github.com/grupo10-CC3S2/Proyecto7-PC4"
+
+setup-v1:
+	docker build -t timeserver:v1 app
+	kubectl cluster-info
+	kubectl apply -f k8s/
+	kubectl get pods
+
+setup-v2:
+	docker build -t timeserver:v2 app
+	kubectl apply -f k8s/
+	kubectl get pods
+
+teardown:
+	flux suspend kustomization kustomization-github
+	kubectl delete all --all --namespace=default --force --grace-period=0
+	docker image rm timeserver:v1
+	docker image rm timeserver:v2
+
+# GitOps
+
+flux-init:
+	flux check --pre
+	flux install
+
+flux-creater:
+	flux create source git repo-github --url=$(REPO) --branch=main --interval=30s --export > ./flux-gitrepository.yaml
+	kubectl apply -f ./flux-gitrepository.yaml
+	
+flux-createk:
+	flux create kustomization kustomization-github --source=GitRepository/repo-github --path="./k8s" --prune=true --interval=30s --export > ./flux-kustomization.yaml
+	kubectl apply -f ./flux-kustomization.yaml
+
+flux-getk:
+	flux get kustomizations
+
+flux-watchk:
+	flux get kustomizations --watch
+
+flux-suspend:
+	flux suspend kustomization kustomization-github
+
+pod-images:
+	kubectl get pods --namespace=default -o json | jq '.items[].spec.containers[] | {pod: .name, container_name: .name, image: .image}'
\ No newline at end of file
diff --git a/README.md b/README.md
index 8dfb58f..a2d2382 100644
--- a/README.md
+++ b/README.md
@@ -11,7 +11,8 @@
 
 1. Construir la imagen Docker local:
    ```sh
-   docker build -t timeserver:latest app
+   docker build -t timeserver:v1 app
+   docker build -t timeserver:v2 app
    ```
 2. Verificar que Kubernetes esta activado:
    ```sh
diff --git a/app/logger_service.py b/app/logger_service.py
new file mode 100644
index 0000000..356a476
--- /dev/null
+++ b/app/logger_service.py
@@ -0,0 +1,48 @@
+import logging
+import time
+import threading
+from datetime import datetime, timezone
+
+logging.basicConfig(
+    level=logging.INFO,
+    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+)
+
+logger = logging.getLogger(__name__)
+
+stop_logging = False
+
+
+def periodic_warning_logs():
+    warning_count = 1
+    logger.info("logs nivel warning")
+
+    while not stop_logging:
+        time.sleep(10)
+        if not stop_logging:
+            timestamp = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
+            logger.warning(f"warning #{warning_count} at {timestamp}")
+            warning_count += 1
+
+
+def periodic_error_logs():
+    error_count = 1
+    logger.info("logs nivel error")
+
+    while not stop_logging:
+        time.sleep(20)
+        if not stop_logging:
+            timestamp = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
+            logger.error(f"error #{error_count} at {timestamp}")
+            error_count += 1
+
+
+def start_background_logging():
+    logger.info("log nivel info start")
+    warning_thread = threading.Thread(target=periodic_warning_logs, daemon=True)
+    warning_thread.start()
+
+    error_thread = threading.Thread(target=periodic_error_logs, daemon=True)
+    error_thread.start()
+
+    logger.info("log nivel info end")
diff --git a/app/server.py b/app/server.py
index c202fec..129c4f7 100644
--- a/app/server.py
+++ b/app/server.py
@@ -1,6 +1,8 @@
 from flask import Flask, Response
 from datetime import datetime, timezone
 from zoneinfo import ZoneInfo
+from logger_service import start_background_logging, logger
+
 
 app = Flask(__name__)
 
@@ -18,4 +20,6 @@ def get_current_time():
 
 
 if __name__ == "__main__":
-    app.run(host='0.0.0.0', port=80)
\ No newline at end of file
+    start_background_logging()
+    logger.info("Flask server starting on 0.0.0.0:80")
+    app.run(host='0.0.0.0', port=80)
diff --git a/flux-gitrepository.yaml b/flux-gitrepository.yaml
new file mode 100644
index 0000000..da2aacb
--- /dev/null
+++ b/flux-gitrepository.yaml
@@ -0,0 +1,11 @@
+---
+apiVersion: source.toolkit.fluxcd.io/v1
+kind: GitRepository
+metadata:
+  name: repo-github
+  namespace: flux-system
+spec:
+  interval: 30s
+  ref:
+    branch: main
+  url: https://github.com/grupo10-CC3S2/Proyecto7-PC4
diff --git a/flux-kustomization.yaml b/flux-kustomization.yaml
new file mode 100644
index 0000000..bb7d6a0
--- /dev/null
+++ b/flux-kustomization.yaml
@@ -0,0 +1,13 @@
+---
+apiVersion: kustomize.toolkit.fluxcd.io/v1
+kind: Kustomization
+metadata:
+  name: kustomization-github
+  namespace: flux-system
+spec:
+  interval: 30s
+  path: ./k8s
+  prune: true
+  sourceRef:
+    kind: GitRepository
+    name: repo-github
diff --git a/k8s/deploy.yaml b/k8s/deploy.yaml
index 31585a8..098e2a4 100644
--- a/k8s/deploy.yaml
+++ b/k8s/deploy.yaml
@@ -2,6 +2,7 @@ apiVersion: apps/v1
 kind: Deployment
 metadata:
   name: timeserver
+  namespace: default
 spec:
   replicas: 3
   selector:
@@ -14,5 +15,5 @@ spec:
     spec:
       containers:
       - name: timeserver-container
-        image: timeserver:latest
+        image: timeserver:v2
         imagePullPolicy: Never
\ No newline at end of file
diff --git a/k8s/service.yaml b/k8s/service.yaml
index 642f9ff..d358ae5 100644
--- a/k8s/service.yaml
+++ b/k8s/service.yaml
@@ -2,6 +2,7 @@ apiVersion: v1
 kind: Service
 metadata:
   name: timeserver
+  namespace: default
 spec:
   selector:
     pod: timeserver-pod
diff --git a/requirements.txt b/requirements.txt
index b025dd9..c4c6180 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -5,7 +5,4 @@ pytest
 pytest-cov
 pytest-mock
 pytest-html
-kubernetes
-pandas
-tabulate
-plotly.express
\ No newline at end of file
+kubernetes
\ No newline at end of file
diff --git a/scripts/log_collector/Img/get_default_name_pods.png b/scripts/Img/get_default_name_pods.png
similarity index 100%
rename from scripts/log_collector/Img/get_default_name_pods.png
rename to scripts/Img/get_default_name_pods.png
diff --git a/scripts/log_collector/Img/get_default_pods.png b/scripts/Img/get_default_pods.png
similarity index 100%
rename from scripts/log_collector/Img/get_default_pods.png
rename to scripts/Img/get_default_pods.png
diff --git a/scripts/log_collector/Img/namespaces.png b/scripts/Img/namespaces.png
similarity index 100%
rename from scripts/log_collector/Img/namespaces.png
rename to scripts/Img/namespaces.png
diff --git a/scripts/log_collector/Img/namspace_default.png b/scripts/Img/namspace_default.png
similarity index 100%
rename from scripts/log_collector/Img/namspace_default.png
rename to scripts/Img/namspace_default.png
diff --git a/scripts/log_collector/Img/namspace_kube.png b/scripts/Img/namspace_kube.png
similarity index 100%
rename from scripts/log_collector/Img/namspace_kube.png
rename to scripts/Img/namspace_kube.png
diff --git a/scripts/log_collector/Img/only_podnames.png b/scripts/Img/only_podnames.png
similarity index 100%
rename from scripts/log_collector/Img/only_podnames.png
rename to scripts/Img/only_podnames.png
diff --git a/scripts/log_collector/Img/sin_namespace.png b/scripts/Img/sin_namespace.png
similarity index 100%
rename from scripts/log_collector/Img/sin_namespace.png
rename to scripts/Img/sin_namespace.png
diff --git a/scripts/log_collector/README-bash.md b/scripts/README-bash.md
similarity index 100%
rename from scripts/log_collector/README-bash.md
rename to scripts/README-bash.md
diff --git a/scripts/log_collector/README-python.md b/scripts/README-python.md
similarity index 100%
rename from scripts/log_collector/README-python.md
rename to scripts/README-python.md
diff --git a/scripts/log_collector/log_collector.py b/scripts/log_collector.py
similarity index 57%
rename from scripts/log_collector/log_collector.py
rename to scripts/log_collector.py
index ab4f1f1..de5609e 100644
--- a/scripts/log_collector/log_collector.py
+++ b/scripts/log_collector.py
@@ -1,37 +1,17 @@
 import os
 import subprocess
 import sys
-from pathlib import Path
-
-
-def find_root_dir(target_folder_name):
-    current = Path(__file__).resolve()
-    while current.name != target_folder_name:
-        if current.parent == current:
-            raise FileNotFoundError(
-                f"No se encontrÃ³ el directorio '{target_folder_name}' hacia arriba desde {__file__}"
-            )
-        current = current.parent
-    return current
-
 
 namespace = sys.argv[1] if len(sys.argv) > 1 else "default"
 
-
-root_dir = find_root_dir("Proyecto7-PC4")
-
-
-logs_dir = root_dir / "logs"
-logs_dir.mkdir(exist_ok=True)
+os.makedirs("logs", exist_ok=True)
 
 
 def get_pods(namespace="default"):
     try:
         result = subprocess.run(
             ["kubectl", "get", "pods", "-n", namespace, "-o", "name"],
-            capture_output=True,
-            text=True,
-            check=True,
+            capture_output=True, text=True, check=True
         )
         pods = [line.replace("pod/", "") for line in result.stdout.strip().splitlines()]
         return pods
@@ -43,31 +23,23 @@ def get_pods(namespace="default"):
 def collect_logs(pods, namespace="default"):
     for pod in pods:
         print(f"Recolectando logds del pod: {pod}")
-        with open(logs_dir / "all_pods.log", "a", encoding="utf-8") as all_log_file:
-            all_log_file.write(
-                f"=================== Logs del pod: {pod} ===================\n"
-            )
+        with open("logs/all_pods.log", "a", encoding="utf-8") as all_log_file:
+            all_log_file.write(f"=================== Logs del pod: {pod} ===================\n")
 
             try:
                 log_result = subprocess.run(
                     ["kubectl", "logs", pod, "-n", namespace],
-                    capture_output=True,
-                    text=True,
-                    check=True,
+                    capture_output=True, text=True, check=True
                 )
 
                 name_pod = pod.replace("timeserver-7c9445b569-", "")
-                pod_log_path = logs_dir / f"{name_pod}.log"
+                pod_log_path = f"logs/{name_pod}.log"
 
                 with open(pod_log_path, "a", encoding="utf-8") as pod_log_file:
                     pod_log_file.write(log_result.stdout)
                 all_log_file.write(log_result.stdout)
-                all_log_file.write(
-                    f"====== RecolecciÃ³n de logs del pod {pod} completada ======\n"
-                )
-                all_log_file.write(
-                    "----------------------------------------------------------\n"
-                )
+                all_log_file.write(f"====== RecolecciÃ³n de logs del pod {pod} completada ======\n")
+                all_log_file.write("----------------------------------------------------------\n")
 
                 print(f"Logs del pod {pod} guardados en {pod_log_path}")
             except subprocess.CalledProcessError as e:
@@ -76,17 +48,15 @@ def collect_logs(pods, namespace="default"):
 
 def get_events(namespace="default"):
     print("RecolecciÃ³n de eventos del cluster:")
-    with open(logs_dir / "all_events.log", "a", encoding="utf-8") as all_log_file:
+    with open("logs/all_events.log", "a", encoding="utf-8") as all_log_file:
         all_log_file.write("=============== Eventos del cluster ===============\n")
         try:
             events_result = subprocess.run(
                 ["kubectl", "get", "events", "-n", namespace],
-                capture_output=True,
-                text=True,
-                check=True,
+                capture_output=True, text=True, check=True
             )
             all_log_file.write(events_result.stdout)
-            print(f"Eventos del clÃºster guardados en {logs_dir / 'all_events.log'}")
+            print("Eventos del clÃºster guardados en log/all_events.log")
         except subprocess.CalledProcessError as e:
             print(f"Error al obtener los eventos: {e.stderr}")
 
diff --git a/scripts/log_collector/log_collector.sh b/scripts/log_collector.sh
similarity index 100%
rename from scripts/log_collector/log_collector.sh
rename to scripts/log_collector.sh
diff --git a/scripts/metric_collector/README-collector.md b/scripts/metric_collector/README-collector.md
deleted file mode 100644
index ab016a3..0000000
--- a/scripts/metric_collector/README-collector.md
+++ /dev/null
@@ -1,42 +0,0 @@
-# Recolector de mÃ©tricas de los Pods y Nodos
-
-Para obtener estÃ¡s mÃ©tricas(uso de CPU, memoria) usaremos `kubectl top`.  Ahora para que esto nos funcione necesitamos tener `metrics-server` instalado en nuestro clÃºster.
-
-1. Verificamos nuestro clÃºster actual, con el comando `kubectl config current-context`, en nuestro caso es docker-desktop. Luego verificamos si `metrics-server` estÃ¡ instalado, lo cual sabemos que aÃºn no lo tenenmos.
-2. Ya que nuestro clÃºster es docker-desktop, procedemos a instalar `metrics-server` de la siguiente manera. 
-    ```sh
-    # Descargar e instalar la versiÃ³n mÃ¡s reciente
-    kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
-
-    # Editamos el deployment
-    kubectl edit deployment metrics-server -n kube-system
-    ```
-    Al ejecutar el Ãºltimo comando se nos abrirÃ¡ un editor de texto. En el cual tenemos que buscar la secciÃ³n
-    ```yaml
-    spec:
-      containers:
-      - args:
-        - --cert-dir=/tmp
-        - --secure-port=4443
-        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
-        - --kubelet-use-node-status-port
-        - --metric-resolution=15s
-    ```
-
-    Al encontrarlo aÃ±adimos `- --kubelet-insecure-tls`.
-
-    ![](imgs/conf-metrics.png) 
-
-3. Guardamos y salimos. Comprobamos que hayamos hecho todos los pasos correctamente y por ende estÃ© instalado correctamente.
-
-    ![](imgs/1.png)
-
-    - kubectl top pods
-
-        ![](imgs/2.png)
-
-    - kubectl top node
-
-        ![](imgs/3.png)
-
-
diff --git a/scripts/metric_collector/README-visualizer.md b/scripts/metric_collector/README-visualizer.md
deleted file mode 100644
index 0251228..0000000
--- a/scripts/metric_collector/README-visualizer.md
+++ /dev/null
@@ -1,90 +0,0 @@
-# VisualizaciÃ³n de mÃ©tricas
-
-## Instalar metrics-server
-kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
-
-
-En caso ejecutemos la lÃ­nea "kubectl top pods -n default" que indique algo como `API no disponible` lo que haremos serÃ¡
-
-### 1.- kubectl get pods -n kube-system
-
-Y verificar que existe un pods llamado metric-server-<numero>-<codigo>
-
-Si verificamos eso, guardamos el nombre del pods, y editaremos su archivo
-
-```bash
-kubectl edit deployment metrics-server -n kube-system
-```
-Esto nos abrirÃ¡ un editor, y cuando haga esto, buscamos lo siguiente:
-```bash
-containers:
-    - args:
-        - --cert-dir=/tmp
-        - --secure-port=10250
-        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
-        - --kubelet-use-node-status-port
-        - --metric-resolution=15s
-```
-Cuando encontremos eso, lo que haremos serÃ¡ agregar la siguiente lÃ­nea
-```bash
-        - --kubelet-insecure-tls
-```
-**Ojo** Tener cuidado con los espacios
-
-Luego guardamos el editor, cerramos el archivo
-### Mal
-En caso hayamos editado mal nos aparecerÃ¡ algo asÃ­ cuando guardemos el archivo
-```bash
-error: deployments.apps "metrics-server" is invalid
-```
-Y nos abrirÃ¡ otro editor
-
-### Bien
-En caso haberlo hecho bien, nos aparecerÃ¡ este mensaje
-```bash
-deployment.apps/metrics-server edited
-```
-
-Ahora con esto, ya podemos ejecutar el comando
-
-```bash
-kubectl top pods -d default
-```
-
-Y nos mostrarÃ¡ el uso de Memory y CPU de los pods que existen en el namespace `default`
-
-AsÃ­ que para la realizaciÃ³n de obtenciÃ³n de mÃ©tricas con `kubectl top` existen 3 formas:
-```bash
-##Comandos para obtener mÃ©tricas de pods y nodes
-# MÃ©tricas de los pods en un namespace en especÃ­fico
-kubectl top pods -n <namespace>
-
-# MÃ©tricas de los pods en el namespace por defecto
-kubectl top pods
-
-# MÃ©tricas de los nodes
-kubectl top nodes
-```
-
-# metric_visualizer.py
-## Vista general
-El script de `metric_visualizar.py` se encarga de generar archivos `.csv` donde guardarÃ¡ las mÃ©tricas obtenidas mediante alguno de los comando anterior segÃºn el tipo de elemento que usemos, y de acuerdo a este archivo se encargarÃ¡ de:
-- Realizar una visualizaciÃ³n simple y ordenada de los datos en la consola mediante el uso de tablas
-- Crear archivos `html` para la visualizaciÃ³n mediante grÃ¡ficos de barras
-
-## FunciÃ³n collect_metrics
-En el archivo `metric_visualizer.py` existen dos funciones de este tipo, uno para los pods `collect_metrics_pods` y otra para los nodos `collect_metric_nodes` esto lo realicÃ© debido a que no se usa el mismo comando para ambos y preferÃ­ mantener un orden con la creaciÃ³n de archivos `csv` en vez de crear un `collect_metric_general` que ejecute ambos, asÃ­ que estas funciones harÃ¡n lo siguiente:
-> collect_metrics_pods(namespaces)
-- Esta funciÃ³n se encargarÃ¡ de revisar todos los `namespace` disponibles en el lista que solicita como argumento, de acuerdo a ello ejecutarÃ¡ el comando `kubectl top pods -d <namespace>` y guardarÃ¡ el resultado en el archivo `<namespace>.csv`, el csv lo creÃ© para que luego sea posible leerlo con la libreria pandas, y de acuerdo a esto, realizar su grÃ¡fico de barras
-
-> collect_metrics_pods(nodes)
-- La funciÃ³n necesitarÃ¡ como argumento, una lista de los nodos disponibles, siendo esta verificaciÃ³n la principal ya que si no hay nodos, no existirÃ¡ algÃºn pod en el sistema, por lo que al asignarle el nombre del nodo, este ejecutarÃ¡ el comando `kubectl top nodes` y el resultado lo guardarÃ¡ en `<node>.csv`
-
-## FunciÃ³n clean_raw_metrics 
-Esta funciÃ³n se encargarÃ¡ de leer el archivo `csv` creado y de acuerdo a esto, con la libreria pandas, lo separarÃ¡ en columnas con el nombre que posee cada columna en el resultado del comando , para asÃ­ manejar los datos como un DataFrame facilitando su limpieza y visualizaciÃ³n posterior
-
-## FunciÃ³n show_console_table
-El objetivo de esta funciÃ³n es para cumplir con el primer requisito de la rÃºbrica para esta tarea, la cuÃ¡l es de mostrar los datos en la consola pero de manera ordenada y simple, asÃ­ que con la libreria tabulate, lo que realicÃ© fue mostrar todos los datos de manera tabulada en la pantalla, haciendo que sea mÃ¡s entendible y fÃ¡cil de leer al momento de ejecutar el script
-
-## Funcion generate_html_graph
-Esta funciÃ³n termina de cumplir el Ãºltimo objetivo de la tarea, la cuÃ¡l es generar un archivo `html` donde sea posible su visualizaciÃ³n, en un primer momento lo quise realizar de manera vertical, pero luego como hay una gran diferencia entre los datos de las columnas, habÃ­a perdida de datos o mejor dicho, no se podÃ­a ver correctamente algunas barras, asÃ­ que para esta funciÃ³n lo que hice fue que los grÃ¡ficos de barras se muestren de manera horizontal, ya que asÃ­ tendrÃ¡ mÃ¡s tamaÃ±o y podrÃ¡ verse el grÃ¡fico correctamente con todas las columnas que presentan los archivos `csv`
\ No newline at end of file
diff --git a/scripts/metric_collector/imgs/1.png b/scripts/metric_collector/imgs/1.png
deleted file mode 100644
index 9bf1041..0000000
Binary files a/scripts/metric_collector/imgs/1.png and /dev/null differ
diff --git a/scripts/metric_collector/imgs/2.png b/scripts/metric_collector/imgs/2.png
deleted file mode 100644
index f70d5ab..0000000
Binary files a/scripts/metric_collector/imgs/2.png and /dev/null differ
diff --git a/scripts/metric_collector/imgs/3.png b/scripts/metric_collector/imgs/3.png
deleted file mode 100644
index 18982f7..0000000
Binary files a/scripts/metric_collector/imgs/3.png and /dev/null differ
diff --git a/scripts/metric_collector/imgs/conf-metrics.png b/scripts/metric_collector/imgs/conf-metrics.png
deleted file mode 100644
index 5d9ca5c..0000000
Binary files a/scripts/metric_collector/imgs/conf-metrics.png and /dev/null differ
diff --git a/scripts/metric_collector/metric_collector.py b/scripts/metric_collector/metric_collector.py
deleted file mode 100644
index f0948a4..0000000
--- a/scripts/metric_collector/metric_collector.py
+++ /dev/null
@@ -1,155 +0,0 @@
-import os
-from pathlib import Path
-import sys
-import subprocess
-import pandas as pd
-from tabulate import tabulate
-import plotly.express as px
-import json
-
-# Comandos para obtener mÃ©tricas de pods y nodes
-# 1.- kubectl top pods -n <namespace>
-# 2.- kubectl top pods
-# 3.- kubectl top nodes
-
-
-def find_root_dir(target_folder_name):
-    """
-    Busca el directorio raÃ­z del proyecto para el nombre de carpeta especificado.
-    """
-    current = Path(__file__).resolve()
-    while current.name != target_folder_name:
-        if current.parent == current:
-            raise FileNotFoundError(
-                f"No se encontrÃ³ el directorio '{target_folder_name}' hacia arriba desde {__file__}"
-            )
-        current = current.parent
-    return current
-
-
-root_dir = find_root_dir("Proyecto7-PC4")
-
-metrics_dir = root_dir / "metrics"
-metrics_dir.mkdir(exist_ok=True)
-
-
-def get_namespaces():
-    namespaces = subprocess.run(
-        ["kubectl", "get", "namespaces", "-o", "name"],
-        capture_output=True,
-        text=True,
-        check=True,
-    )
-    all_namespaces = [
-        line.replace("namespace/", "")
-        for line in namespaces.stdout.strip().splitlines()
-    ]
-    return all_namespaces
-
-
-def get_nodes():
-    nodes = subprocess.run(
-        ["kubectl", "get", "nodes", "-o", "name"],
-        capture_output=True,
-        text=True,
-        check=True,
-    )
-    all_nodes = [
-        line.replace("node/", "") for line in nodes.stdout.strip().splitlines()
-    ]
-    return all_nodes
-
-
-def collect_metrics__pods(namespaces):
-    pods_dir = metrics_dir / "pods"
-    pods_dir.mkdir(exist_ok=True)
-    print("Recolectando mÃ©tricas de todos los pods...")
-    for names in namespaces:
-        with open(
-            pods_dir / f"{names}_metrics.csv", "a", encoding="utf-8"
-        ) as pod_metrics_file:
-            try:
-                metrics_result = subprocess.run(
-                    ["kubectl", "top", "pods", "-n", names],
-                    capture_output=True,
-                    text=True,
-                    check=True,
-                )
-                pod_metrics_file.write(metrics_result.stdout)
-                lines = metrics_result.stdout.strip().split("\n")
-                if len(lines) > 1:
-                    headers = lines[0].split()
-                    metrics = []
-
-                    for line in lines[1:]:
-                        values = line.split()
-                        metrics.append(dict(zip(headers, values)))
-
-                    json_path = pods_dir / f"{names}_metrics.json"
-                    with open(json_path, "w", encoding="utf-8") as jf:
-                        json.dump(metrics, jf, indent=2)
-            except subprocess.CalledProcessError as e:
-                print(
-                    f"Error al obtener mÃ©tricas de los pods en el namespace {names}: {e.stderr}"
-                )
-    path = metrics_dir / "pods"
-    archivos = os.listdir(path)
-    print(f"RecolecciÃ³n de mÃ©tricas de pods completada y guardados en: {archivos}")
-    print("=========================================================")
-
-
-def collect_metrics__nodes(nodes):
-    nodes_dir = metrics_dir / "nodes"
-    nodes_dir.mkdir(exist_ok=True)
-    print("Recolectando mÃ©tricas de todos los nodos...")
-    for node in nodes:
-        with open(
-            nodes_dir / f"{node}_metrics.csv", "a", encoding="utf-8"
-        ) as node_metrics_file:
-            try:
-                metrics_result = subprocess.run(
-                    ["kubectl", "top", "nodes"],
-                    capture_output=True,
-                    text=True,
-                    check=True,
-                )
-                node_metrics_file.write(metrics_result.stdout)
-                lines = metrics_result.stdout.strip().split("\n")
-                if len(lines) > 1:
-                    headers = lines[0].split()
-                    metrics = []
-
-                    for line in lines[1:]:
-                        values = line.split()
-                        metrics.append(dict(zip(headers, values)))
-
-                    json_path = nodes_dir / f"{node}_metrics.json"
-                    with open(json_path, "w", encoding="utf-8") as jf:
-                        json.dump(metrics, jf, indent=2)
-            except subprocess.CalledProcessError as e:
-                print(f"Error al obtener mÃ©tricas del nodo {node}: {e.stderr}")
-    path = metrics_dir / "nodes"
-    archivos = os.listdir(path)
-    print(f"RecolecciÃ³n de mÃ©tricas de pods completada y guardados en: {archivos}")
-    print("=========================================================")
-
-
-def main():
-    nodes = get_nodes()
-    if not nodes:
-        print("No se encontraron nodos.")
-    else:
-        print(f"Nodos encontrados: {', '.join(nodes)}")
-        print("=========================================================")
-        name = get_namespaces()
-        if not name:
-            print("No se encontraron namespaces.")
-        else:
-            print(f"Namespaces encontrados: {', '.join(name)}")
-            print("=========================================================")
-            collect_metrics__pods(name)
-            collect_metrics__nodes(nodes)
-
-
-if __name__ == "__main__":
-    main()
diff --git a/scripts/metric_collector/metric_visualizer.py b/scripts/metric_collector/metric_visualizer.py
deleted file mode 100644
index e627863..0000000
--- a/scripts/metric_collector/metric_visualizer.py
+++ /dev/null
@@ -1,138 +0,0 @@
-import os
-from pathlib import Path
-import sys
-import subprocess
-import pandas as pd
-from tabulate import tabulate
-import plotly.express as px
-
-# Comandos para obtener mÃ©tricas de pods y nodes
-# 1.- kubectl top pods -n <namespace>
-# 2.- kubectl top pods
-# 3.- kubectl top nodes
-
-
-def find_root_dir(target_folder_name):
-    '''
-    Busca el directorio raÃ­z del proyecto para el nombre de carpeta especificado.
-    '''
-    current = Path(__file__).resolve()
-    while current.name != target_folder_name:
-        if current.parent == current:
-            raise FileNotFoundError(f"No se encontrÃ³ el directorio '{target_folder_name}' hacia arriba desde {__file__}")
-        current = current.parent
-    return current
-
-
-root_dir = find_root_dir("Proyecto7-PC4")
-
-metrics_dir = root_dir / "metrics"
-metrics_dir.mkdir(exist_ok=True)
-
-
-# VisualizaciÃ³n de mÃ©tricas
-def clean_raw_metrics_pods(pod_path):
-    df = pd.read_csv(pod_path, sep=r'\s+')
-    df.columns = ["POD", "CPU_cores(m)", "MEM_bytes(Mi)"]
-    df["CPU_cores(m)"] = df["CPU_cores(m)"].str.replace("m", "", regex=False).astype(int)
-    df["MEM_bytes(Mi)"] = df["MEM_bytes(Mi)"].str.replace("Mi", "", regex=False).astype(int)
-
-    return df
-
-
-def clean_raw_metrics_nodes(node_path):
-    df = pd.read_csv(node_path, sep=r'\s+')
-
-    df.columns = ["NODE", "CPU_cores(m)", "CPU_%", "MEM_bytes(Mi)", "MEM_%"]
-
-    df["CPU_cores(m)"] = df["CPU_cores(m)"].str.replace("m", "", regex=False).astype(str)
-    df["CPU_%"] = df["CPU_%"].str.replace("%", "", regex=False).astype(str)
-    df["MEM_bytes(Mi)"] = df["MEM_bytes(Mi)"].str.replace("Mi", "", regex=False).astype(str)
-    df["MEM_%"] = df["MEM_%"].str.replace("%", "", regex=False).astype(str)
-
-    return df
-
-
-def show_console_table(df, name):
-    print(f"\n=== Tabla resumida de mÃ©tricas de {name} ===")
-    print(tabulate(df, headers='keys', tablefmt='fancy_grid'))
-
-
-# Ingresar pods or nodes
-def visualize_metrics_console():
-    path = metrics_dir
-    folders = os.listdir(path)
-    for folder in folders:
-        files_path = path / folder
-        archivos = os.listdir(files_path)
-        for file in archivos:
-            if not file.endswith(".csv"):
-                continue
-            else:
-                if folder == "pods":
-                    with open(files_path / file, "r", encoding="utf-8") as f:
-                        read = f.read()
-                    if not read:
-                        print(f"Las mÃ©tricas de {file} no estÃ¡n disponibles.")
-                    else:
-                        df = clean_raw_metrics_pods(files_path / file)
-                        show_console_table(df, file)
-                        generate_html_graph_pods(df, files_path / f"{file.split('.')[0]}.html", f"{file.split('.')[0]}.html")
-                elif folder == "nodes":
-                    with open(files_path / file, "r", encoding="utf-8") as f:
-                        read = f.read()
-                    if not read:
-                        print(f"Las mÃ©tricas de {file} no estÃ¡n disponibles.")
-                    else:
-                        df = clean_raw_metrics_nodes(files_path / file)
-                        show_console_table(df, file)
-                        generate_html_graph_nodes(df, files_path / f"{file.split('.')[0]}.html", f"{file.split('.')[0]}.html")
-
-
-def generate_html_graph_pods(df, output_path, name):
-    df_long = df.melt(id_vars="POD", value_vars=["CPU_cores(m)", "MEM_bytes(Mi)"], var_name="Recurso", value_name="Valor")
-
-    df_long["Recurso"] = df_long["Recurso"].replace({
-        "CPU_cores(m)": "CPU (m)",
-        "MEM_bytes(Mi)": "Memoria (Mi)"
-    })
-
-    fig = px.bar(df_long, y="POD", x="Valor", color="Recurso", barmode="group", orientation="h", title="Uso de CPU y Memoria por Pod")
-    fig.update_traces(texttemplate='%{x}', textposition='outside')
-    fig.write_html(output_path)
-    print(f"\nGrÃ¡fico HTML guardado en: {name}")
-
-
-def generate_html_graph_nodes(df, output_path, name):
-    df["CPU_cores(m)"] = df["CPU_cores(m)"].astype(float)
-    df["CPU_%"] = df["CPU_%"].astype(float)
-    df["MEM_bytes(Mi)"] = df["MEM_bytes(Mi)"].astype(float)
-    df["MEM_%"] = df["MEM_%"].astype(float)
-
-    df_long = df.melt(
-        id_vars="NODE",
-        value_vars=["CPU_cores(m)", "CPU_%", "MEM_bytes(Mi)", "MEM_%"],
-        var_name="Recurso",
-        value_name="Valor"
-    )
-
-    df_long["Recurso"] = df_long["Recurso"].replace({
-        "CPU_cores(m)": "CPU (m)",
-        "CPU_%": "CPU (%)",
-        "MEM_bytes(Mi)": "Memoria (Mi)",
-        "MEM_%": "Memoria (%)"
-    })
-
-    fig = px.bar(df_long, y="NODE", x="Valor", color="Recurso", barmode="group", orientation="h", title="Uso de Recursos por Nodo (CPU y Memoria)")
-
-    fig.update_traces(texttemplate='%{x}', textposition='outside')
-    fig.write_html(output_path)
-    print(f"\nGrÃ¡fico HTML guardado en: {name}")
-
-
-def main():
-    visualize_metrics_console()
-
-
-if __name__ == "__main__":
-    main()
diff --git a/tests/test_collector_log.py b/tests/test_collector_log.py
index 2b177f0..a4c872f 100644
--- a/tests/test_collector_log.py
+++ b/tests/test_collector_log.py
@@ -1,6 +1,6 @@
 import pytest
 import subprocess
-from scripts.log_collector.log_collector import get_pods, collect_logs, get_events
+from scripts.log_collector import get_pods, collect_logs, get_events
 
 namespace = "default"
 
@@ -29,7 +29,10 @@ def test_collect_logs_xfail_and_fail():
         pytest.xfail("No hay pods disponibles en el namespace indicado")
 
     collect_logs(pods[0], namespace=namespace2)
-    subprocess.run(["rm", "-r", "logs"], capture_output=True, text=True, check=True)
+    subprocess.run(
+        ["rm", "-r", "logs"],
+        capture_output=True, text=True, check=True
+    )
 
 
 @pytest.mark.xfail(reason="AlgÃºn pod no estÃ¡ disponible")
@@ -39,4 +42,7 @@ def test_collect_logs_xfail_not_fail():
         pytest.xfail("No hay pods disponibles en el namespace indicado")
 
     collect_logs(pods[0], namespace=namespace2)
-    subprocess.run(["rm", "-r", "logs"], capture_output=True, text=True, check=True)
+    subprocess.run(
+        ["rm", "-r", "logs"],
+        capture_output=True, text=True, check=True
+    )
diff --git a/tests/test_metric_visualizer.py b/tests/test_metric_visualizer.py
deleted file mode 100644
index 21fbb90..0000000
--- a/tests/test_metric_visualizer.py
+++ /dev/null
@@ -1,32 +0,0 @@
-import pytest
-from scripts.metric_collector import metric_collector
-from scripts.metric_collector import metric_visualizer
-
-
-root_dir = metric_visualizer.find_root_dir("Proyecto7-PC4")
-
-
-def setup_module(module):
-    # Se ejecuta una vez antes de cualquier test en este archivo
-    print("\n[setup] Ejecutando dependencias...")
-    metric_collector.main()  # si aplica
-    metric_visualizer.main()  # o alguna funciÃ³n que prepare el entorno
-
-
-@pytest.mark.xfail(reason="El directorio no existe")
-def test_not_fing_root_dir():
-    assert metric_visualizer.find_root_dir("non_existent_dir")
-
-
-def test_find_root_dir():
-    root = metric_visualizer.find_root_dir("Proyecto7-PC4")
-    assert root.is_dir()
-
-
-def test_clean_raw_metrics_pods():
-    pod_path = root_dir / "metrics" / "pods" / "default_metrics.csv"
-    df = metric_visualizer.clean_raw_metrics_pods(pod_path)
-    assert not df.empty
-    assert "POD" in df.columns
-    assert "CPU_cores(m)" in df.columns
-    assert "MEM_bytes(Mi)" in df.columns
